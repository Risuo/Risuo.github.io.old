
<head>
<meta charset="UTF-8" />
<title>Building Identification</title>

<!-- bs4 css -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.1.0/css/bootstrap.min.css"/>

<!-- jQuery library -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<!-- Popper JS -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.0/umd/popper.min.js"></script>

<!-- Latest compiled JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.1.0/js/bootstrap.min.js"></script>

<!-- TensorFlow.js script -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"> </script>
	
<!-- canvas script -->
<!--
<script src="fabric.js"></script>
-->
	
<!-- main script -->
<!--
<script src = "main.js" > </script>
 -->

<!-- map script -->
<script src = "map.js" > </script>

<!-- main css -->
<link rel = "stylesheet" href="main.css" > 
	
</head>



<body>
<nav class="navbar navbar-expand-sm bg-light navbar-light">
  <!-- Brand/logo -->
  <a class="navbar-brand" href="#"><h1>Building Identification - from Trained from Scratch U-net to<br/>
      state of the art Transfer learning Detectron2 implementation</h1></a>
  </nav>

<div class="container-fluid">

<blockquote class="blockquote text-justify" style="margin:30px;">
    <p>Image identification is complicated. </p>
    <p>My journey from developing a self-trained simple model, all the way to a (not awful) general-purpose instance segmentation model will be detailed within.
    The journey was long (multiple months) and arduous (hours and hours debugging) but rewarding (look at that! it actually sees buildings!) and (wow, top 10% in a
    prize-money competition!). </p>
    <p>I began this journey just about 5 months ago, and I'll try to give you as many details as possible, but first the results!</p>
    <p>Here is a simple Google Earth map implementation window, within which you can select anywhere on the globe, and send a request to have the
    trained model infer buildings on. Try fooling around with the orientation (rotate the North/South) or zoom levels and see how it changes the prediction.</p>
</blockquote>




    <div id="map2_parent">
        <div id="map2"></div>
    </div>

    <!-- Replace the value of the key parameter with your own API key. -->
    <script async defer
    src="https://maps.googleapis.com/maps/api/js?key=AIzaSyBrVT1spoPFTqwPqIprN5lWWK7Ddz41QjI&callback=initMap">
    </script>


    <p></p>
    <p>Details on the methodology and process begin here:</p>


</div>
<!--
    <p> This page leans heavily on the Sketcher project develoepd by Zaid Alyafeai. His page is available here: <a href='https://zaidalyafeai.github.io/sketcher/'  target = "_blank"> Sketcher</a>. The CNN on this page was trained to recognize all 345 classes using the quick draw <a href='https://github.com/googlecreativelab/quickdraw-dataset' target = "_blank"> dataset</a>.
    <p> This project is an extension of Zaid's implementation. Rather than limiting to 100 classes, I wanted to see how it would perform under all 345 classes.<p>
    <p> Unsurprisingly, the accuracy is lower, however with training the model was able to achieve almost 90% Top 5 accuracy.<p>
    <p> The model on this page was trained on the following CNN: <p>
    <img src="https://raw.githubusercontent.com/Risuo/Risuo.github.io/master/Sketcher/Images/CNN_Model.PNG?raw=true" alt="CNN_Model.PNG">
    <p> This model was arrived at through 50 rounds of scikit-optimize to select from the following parameters: <p>
    <img src="https://raw.githubusercontent.com/Risuo/Risuo.github.io/master/Sketcher/Images/Optimize_Parameters.PNG?raw=true" alt="Optimize_Parameter.PNG">
    <p> And resulted in the following convergence plot:<p>
    <img src="https://raw.githubusercontent.com/Risuo/Risuo.github.io/master/Sketcher/Images/Convergence_plot.PNG?raw=true" alt="Convergence_plot.PNG">
    <p> Smaller, 60000 length train and 5000 length validation sets were used for the optimization.<p>
    <p> The Training/Testing dataset had 1656000 and 20% validation split value, trained as such:<p>
    <img src="https://raw.githubusercontent.com/Risuo/Risuo.github.io/master/Sketcher/Images/training.PNG?raw=true" alt="training.PNG">
    <p> The results of the loss graph more clearly shows slight overfitting, and a more optimal model around epoch 18.<p>
    <img src="https://raw.githubusercontent.com/Risuo/Risuo.github.io/master/Sketcher/Images/Accuracy_over_epoch.PNG?raw=true" alt="Accuracy_over_epoch.PNG">
    <img src="https://raw.githubusercontent.com/Risuo/Risuo.github.io/master/Sketcher/Images/Loss_over_epoch.PNG?raw=true" alt="Loss_over_epoch.PNG">
    <p> The link to an earlier, simpler* Colaboratory Notebook prototype with only 160 classes is available here: <a href='https://colab.research.google.com/github/Risuo/Springboard/blob/master/Revised_TPU_Quick_Draw_Data.ipynb' target = "_blank"> Colab</a>
    <small> *Fun note, the prototype was trained using Google's Tensor Processing Unit (TPU) </small><p>
    <footer class="blockquote-footer">Peter Miller</footer>
</div>
-->